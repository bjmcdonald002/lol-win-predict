{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e9c5eed-f8dd-4178-b135-282702a2cd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCLR Subsample Results (2,500 rows):\n",
      "Accuracy:  0.8173\n",
      "F1 Score:  0.8218\n",
      "ROC AUC:   0.8950\n"
     ]
    }
   ],
   "source": [
    "#for comparison purposes, we are running various classification methods on this data and comparing results\n",
    "#we use a 2500 observation random sample, determine which models perform best, run on full dataset, then validate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import numpy.linalg as LA\n",
    "\n",
    "# Load the data\n",
    "df_csv = pd.read_csv(\"league_data.csv\", dtype={'win': str})\n",
    "\n",
    "# Drop irrelevant/metadata columns\n",
    "columns_to_drop = [\n",
    "    'game_id', 'game_version', 'participant_id', 'puuid', 'summoner_name', 'summoner_id',\n",
    "    'solo_tier', 'solo_rank', 'solo_lp', 'solo_wins', 'solo_losses',\n",
    "    'flex_tier', 'flex_rank', 'flex_lp', 'flex_wins', 'flex_losses',\n",
    "    'champion_mastery_lastPlayTime', 'champion_mastery_lastPlayTime_utc',\n",
    "    'champion_id', 'map_id', 'platform_id', 'game_type', 'team_id',\n",
    "    'game_start_utc', 'queue_id', 'game_mode'\n",
    "]\n",
    "\n",
    "# Filter for CLASSIC + ranked solo/duo games\n",
    "df_filtered = df_csv[(df_csv['game_mode'] == 'CLASSIC') & (df_csv['queue_id'] == 420)].copy()\n",
    "\n",
    "# Drop metadata columns\n",
    "df_filtered_cleaned = df_filtered.drop(columns=[col for col in columns_to_drop if col in df_filtered.columns])\n",
    "\n",
    "# Convert 'win' column to binary\n",
    "df_filtered_cleaned['win'] = (df_filtered_cleaned['win'] == 'TRUE').astype(int)\n",
    "\n",
    "# Drop non-numeric/categorical columns (and item columns)\n",
    "df_numeric_only = df_filtered_cleaned.drop(columns=df_filtered_cleaned.select_dtypes(include=['object', 'category']).columns)\n",
    "df_numeric_only = df_numeric_only.drop(columns=[col for col in df_numeric_only.columns if col.startswith(\"item\")])\n",
    "\n",
    "# Final predictor/response matrices\n",
    "X = df_numeric_only.drop(columns=['win']).fillna(df_numeric_only.mean())\n",
    "y = df_numeric_only['win']\n",
    "\n",
    "# --- Subsample preparation (2,500 observations) ---\n",
    "sample_indices = np.random.choice(X.index, size=2500, replace=False)\n",
    "X_sample = X.loc[sample_indices]\n",
    "y_sample = y.loc[sample_indices]\n",
    "\n",
    "# --- Robust PCA Manual Calculation of L and S ---\n",
    "def robust_pca_fast(M, max_iter=150, tol=1e-4):\n",
    "    def shrinkage_operator(x, tau):\n",
    "        return np.sign(x) * np.maximum(np.abs(x) - tau, 0.)\n",
    "    def svd_thresholding_operator(X, tau):\n",
    "        U, S, Vh = LA.svd(X, full_matrices=False)\n",
    "        S_thresh = shrinkage_operator(S, tau)\n",
    "        return U @ np.diag(S_thresh) @ Vh\n",
    "    S = np.zeros_like(M)\n",
    "    Y = np.zeros_like(M)\n",
    "    mu = np.prod(M.shape) / (4.0 * LA.norm(M, ord=1))\n",
    "    mu_inv = 1.0 / mu\n",
    "    lam = 1.0 / np.sqrt(np.max(M.shape))\n",
    "    for _ in range(max_iter):\n",
    "        L = svd_thresholding_operator(M - S + mu_inv * Y, mu_inv)\n",
    "        S = shrinkage_operator(M - L + mu_inv * Y, lam * mu_inv)\n",
    "        Y = Y + mu * (M - L - S)\n",
    "        error = LA.norm(M - L - S, ord='fro')\n",
    "        if error < tol:\n",
    "            break\n",
    "    return L, S\n",
    "\n",
    "# --- Preprocessing and robust PCA ---\n",
    "scaler_raw = StandardScaler()\n",
    "X_scaled_sample = scaler_raw.fit_transform(X_sample)\n",
    "L_sample, S_sample = robust_pca_fast(X_scaled_sample)\n",
    "\n",
    "# --- Train/test split and scale ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(L_sample, y_sample, test_size=0.3, stratify=y_sample)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- PCA and Logistic Regression ---\n",
    "pca = PCA(n_components=10)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_pca, y_train)\n",
    "y_pred = log_reg.predict(X_test_pca)\n",
    "y_proba = log_reg.predict_proba(X_test_pca)[:, 1]\n",
    "\n",
    "# --- Performance output ---\n",
    "print(\"PCLR Subsample Results (2,500 rows):\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_score(y_test, y_proba):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce67363-9e47-4b29-93c6-3d6e87e4cdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression WITHOUT PCA\n",
      "\n",
      "L2 Regularization:\n",
      "Accuracy:  0.8867\n",
      "F1 Score:  0.8877\n",
      "ROC AUC:   0.9532\n",
      "\n",
      "L1 Regularization:\n",
      "Accuracy:  0.8840\n",
      "F1 Score:  0.8848\n",
      "ROC AUC:   0.9527\n"
     ]
    }
   ],
   "source": [
    "#logistic regression, no PCA, l1 & L2 regularization\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Subsample (2500 for quick performance) ---\n",
    "sample_indices = np.random.choice(X.index, size=2500, replace=False)\n",
    "X_sample = X.loc[sample_indices]\n",
    "y_sample = y.loc[sample_indices]\n",
    "\n",
    "# --- Split and scale ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.3, stratify=y_sample)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- L2 (Ridge) Regularization ---\n",
    "log_reg_l2 = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
    "log_reg_l2.fit(X_train_scaled, y_train)\n",
    "y_pred_l2 = log_reg_l2.predict(X_test_scaled)\n",
    "y_proba_l2 = log_reg_l2.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# --- L1 (Lasso) Regularization ---\n",
    "log_reg_l1 = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000)\n",
    "log_reg_l1.fit(X_train_scaled, y_train)\n",
    "y_pred_l1 = log_reg_l1.predict(X_test_scaled)\n",
    "y_proba_l1 = log_reg_l1.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# --- Print results ---\n",
    "print(\"Logistic Regression WITHOUT PCA\\n\")\n",
    "\n",
    "print(\"L2 Regularization:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_l2):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_pred_l2):.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_score(y_test, y_proba_l2):.4f}\\n\")\n",
    "\n",
    "print(\"L1 Regularization:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_l1):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_pred_l1):.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_score(y_test, y_proba_l1):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e04bf8a-4878-4c5a-9929-0c90bc1fbcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results:\n",
      "Accuracy:  0.7760\n",
      "F1 Score:  0.7789\n",
      "ROC AUC:   0.7760\n"
     ]
    }
   ],
   "source": [
    "#decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Subsample (reuse or reset this as needed) ---\n",
    "sample_indices = np.random.choice(X.index, size=2500, replace=False)\n",
    "X_sample = X.loc[sample_indices]\n",
    "y_sample = y.loc[sample_indices]\n",
    "\n",
    "# --- Train/test split and scale ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.3, stratify=y_sample)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Train Decision Tree ---\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test_scaled)\n",
    "y_proba_tree = tree_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# --- Evaluate performance ---\n",
    "print(\"Decision Tree Results:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_tree):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_pred_tree):.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_score(y_test, y_proba_tree):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "458cc7a5-99ce-4717-a984-e52a7f8d67d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "Accuracy:  0.8640\n",
      "F1 Score:  0.8654\n",
      "ROC AUC:   0.9377\n"
     ]
    }
   ],
   "source": [
    "#random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Subsample (reuse if already defined) ---\n",
    "sample_indices = np.random.choice(X.index, size=2500, replace=False)\n",
    "X_sample = X.loc[sample_indices]\n",
    "y_sample = y.loc[sample_indices]\n",
    "\n",
    "# --- Train/test split and scale ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.3, stratify=y_sample)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Train Random Forest ---\n",
    "forest_clf = RandomForestClassifier(n_estimators=100)\n",
    "forest_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_forest = forest_clf.predict(X_test_scaled)\n",
    "y_proba_forest = forest_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# --- Evaluate performance ---\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_forest):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_pred_forest):.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_score(y_test, y_proba_forest):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f634bafe-3f1b-4b1b-8ee6-4ad0d3aaeac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Results:\n",
      "Accuracy:  0.8733\n",
      "F1 Score:  0.8742\n",
      "ROC AUC:   0.9469\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Subsample (2500 rows for speed) ---\n",
    "sample_indices = np.random.choice(X.index, size=2500, replace=False)\n",
    "X_sample = X.loc[sample_indices]\n",
    "y_sample = y.loc[sample_indices]\n",
    "\n",
    "# --- Train/test split and scale ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.3, stratify=y_sample)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Train XGBoost ---\n",
    "xgb_clf = XGBClassifier(eval_metric='logloss')\n",
    "xgb_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_xgb = xgb_clf.predict(X_test_scaled)\n",
    "y_proba_xgb = xgb_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# --- Evaluate performance ---\n",
    "print(\"XGBoost Results:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_score(y_test, y_proba_xgb):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b53cd65d-ec1f-4297-a987-201dd18c2831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Results:\n",
      "Accuracy:  0.8693\n",
      "F1 Score:  0.8727\n",
      "ROC AUC:   0.9524\n"
     ]
    }
   ],
   "source": [
    "#lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Subsample (2500 rows for consistency) ---\n",
    "sample_indices = np.random.choice(X.index, size=2500, replace=False)\n",
    "X_sample = X.loc[sample_indices]\n",
    "y_sample = y.loc[sample_indices]\n",
    "\n",
    "# --- Train/test split and scale ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.3, stratify=y_sample)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "\n",
    "# --- Train LightGBM ---\n",
    "lgbm_clf = LGBMClassifier(verbose=-1)\n",
    "lgbm_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_lgbm = lgbm_clf.predict(X_test_scaled)\n",
    "y_proba_lgbm = lgbm_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# --- Evaluate performance ---\n",
    "print(\"LightGBM Results:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_lgbm):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_pred_lgbm):.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_score(y_test, y_proba_lgbm):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b772a541-26f2-473e-b83a-59c75e770d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Results:\n",
      "Accuracy:  0.8720\n",
      "F1 Score:  0.8703\n",
      "ROC AUC:   0.9547\n"
     ]
    }
   ],
   "source": [
    "#support vector machines\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Subsample (2500 rows for consistency) ---\n",
    "sample_indices = np.random.choice(X.index, size=2500, replace=False)\n",
    "X_sample = X.loc[sample_indices]\n",
    "y_sample = y.loc[sample_indices]\n",
    "\n",
    "# --- Train/test split and scale ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.3, stratify=y_sample)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Train SVM (with probability enabled for ROC AUC) ---\n",
    "svm_clf = SVC(probability=True, kernel='rbf')\n",
    "svm_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_svm = svm_clf.predict(X_test_scaled)\n",
    "y_proba_svm = svm_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# --- Evaluate performance ---\n",
    "print(\"Support Vector Machine Results:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_svm):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_pred_svm):.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_score(y_test, y_proba_svm):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ce1a411-2d84-433d-9587-996780bbec65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Results:\n",
      "Accuracy:  0.7787\n",
      "F1 Score:  0.7769\n",
      "ROC AUC:   0.8473\n"
     ]
    }
   ],
   "source": [
    "#k nearest neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Subsample (2500 rows for consistency) ---\n",
    "sample_indices = np.random.choice(X.index, size=2500, replace=False)\n",
    "X_sample = X.loc[sample_indices]\n",
    "y_sample = y.loc[sample_indices]\n",
    "\n",
    "# --- Train/test split and scale ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.3, stratify=y_sample)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Train KNN ---\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_knn = knn_clf.predict(X_test_scaled)\n",
    "y_proba_knn = knn_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# --- Evaluate performance ---\n",
    "print(\"K-Nearest Neighbors Results:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_knn):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_pred_knn):.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_score(y_test, y_proba_knn):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2213e8db-5077-43d4-9025-c916c98609e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Results:\n",
      "Accuracy:  0.7520\n",
      "F1 Score:  0.7207\n",
      "ROC AUC:   0.8250\n"
     ]
    }
   ],
   "source": [
    "#naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Subsample (2500 rows for consistency) ---\n",
    "sample_indices = np.random.choice(X.index, size=2500, replace=False)\n",
    "X_sample = X.loc[sample_indices]\n",
    "y_sample = y.loc[sample_indices]\n",
    "\n",
    "# --- Train/test split and scale ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.3, stratify=y_sample)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Train Naive Bayes ---\n",
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_nb = nb_clf.predict(X_test_scaled)\n",
    "y_proba_nb = nb_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# --- Evaluate performance ---\n",
    "print(\"Naive Bayes Results:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_nb):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_pred_nb):.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_score(y_test, y_proba_nb):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9727e336-d259-4be2-9834-7f462f910cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network (MLP) Results:\n",
      "Accuracy:  0.8640\n",
      "F1 Score:  0.8587\n",
      "ROC AUC:   0.9371\n"
     ]
    }
   ],
   "source": [
    "#MLP classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Subsample (2500 rows for consistency) ---\n",
    "sample_indices = np.random.choice(X.index, size=2500, replace=False)\n",
    "X_sample = X.loc[sample_indices]\n",
    "y_sample = y.loc[sample_indices]\n",
    "\n",
    "# --- Train/test split and scale ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.3, stratify=y_sample)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Train Neural Network (MLP) ---\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500)\n",
    "mlp_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_mlp = mlp_clf.predict(X_test_scaled)\n",
    "y_proba_mlp = mlp_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# --- Evaluate performance ---\n",
    "print(\"Neural Network (MLP) Results:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_mlp):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_pred_mlp):.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_score(y_test, y_proba_mlp):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8beb917c-81ac-464d-9741-2528c9d873c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Neural Network Results (Full Dataset):\n",
      "Accuracy:  0.8795\n",
      "F1 Score:  0.8780\n",
      "ROC AUC:   0.9479\n"
     ]
    }
   ],
   "source": [
    "#MLP: tinkering with hyperparameters and running on full dataset: two hidden layers (128, 64), relu activation, adam optimizer, 1000 epochs\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# --- Full dataset (already preprocessed into X and y) ---\n",
    "X_full = X.copy()\n",
    "y_full = y.copy()\n",
    "\n",
    "# --- Train/test split and scale ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.3, stratify=y_full)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Tuned MLP Neural Network ---\n",
    "mlp_tuned = MLPClassifier(hidden_layer_sizes=(128, 64), activation='relu', solver='adam', max_iter=1000)\n",
    "mlp_tuned.fit(X_train_scaled, y_train)\n",
    "y_pred_mlp = mlp_tuned.predict(X_test_scaled)\n",
    "y_proba_mlp = mlp_tuned.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# --- Evaluate performance ---\n",
    "print(\"Tuned Neural Network Results (Full Dataset):\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_mlp):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_pred_mlp):.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_score(y_test, y_proba_mlp):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0056dde2-db4a-439d-838a-9518524f6a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Results (Full Dataset):\n",
      "Accuracy:  0.8587\n",
      "F1 Score:  0.8515\n",
      "ROC AUC:   0.9375\n"
     ]
    }
   ],
   "source": [
    "#lightGBM on full dataset\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# --- Full dataset (already preprocessed into X and y) ---\n",
    "X_full = X.copy()\n",
    "y_full = y.copy()\n",
    "\n",
    "# --- Train/test split and scale ---\n",
    "# --- Train/test split and scale ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.3, stratify=y_sample)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "\n",
    "# --- Train LightGBM ---\n",
    "lgbm_clf = LGBMClassifier(verbose=-1)\n",
    "lgbm_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_lgbm = lgbm_clf.predict(X_test_scaled)\n",
    "y_proba_lgbm = lgbm_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# --- Evaluate performance ---\n",
    "print(\"LightGBM Results (Full Dataset):\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_lgbm):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_pred_lgbm):.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_score(y_test, y_proba_lgbm):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ee57ff7-f87e-4d2d-aa68-b123abd2bcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Results (Full Dataset):\n",
      "Accuracy:  0.8911\n",
      "F1 Score:  0.8909\n",
      "ROC AUC:   0.9642\n"
     ]
    }
   ],
   "source": [
    "#XGBoost on full dataset\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# --- Full dataset (already preprocessed into X and y) ---\n",
    "X_full = X.copy()\n",
    "y_full = y.copy()\n",
    "\n",
    "# --- Train/test split and scale ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.3, stratify=y_full)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Train XGBoost ---\n",
    "xgb_clf = XGBClassifier(eval_metric='logloss')\n",
    "xgb_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_xgb = xgb_clf.predict(X_test_scaled)\n",
    "y_proba_xgb = xgb_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# --- Evaluate performance ---\n",
    "print(\"XGBoost Results (Full Dataset):\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_score(y_test, y_proba_xgb):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95ff6f26-5ecf-48b3-b272-38a925117434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Logistic Regression Results (Full Dataset):\n",
      "Accuracy:  0.8807\n",
      "F1 Score:  0.8781\n",
      "ROC AUC:   0.9486\n"
     ]
    }
   ],
   "source": [
    "#L1 Logistic Regression on full dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# --- Full dataset (already preprocessed into X and y) ---\n",
    "X_full = X.copy()\n",
    "y_full = y.copy()\n",
    "\n",
    "# --- Train/test split and scale ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.3, stratify=y_full)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- L1 (Lasso) Logistic Regression ---\n",
    "log_reg_l1 = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000)\n",
    "log_reg_l1.fit(X_train_scaled, y_train)\n",
    "y_pred_l1 = log_reg_l1.predict(X_test_scaled)\n",
    "y_proba_l1 = log_reg_l1.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# --- Evaluate performance ---\n",
    "print(\"L1 Logistic Regression Results (Full Dataset):\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_l1):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_pred_l1):.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_score(y_test, y_proba_l1):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0337368-4167-48ee-84ca-f519046ed6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM (Shuffled Labels):\n",
      "Accuracy:  0.5030\n",
      "F1 Score:  0.5033\n",
      "ROC AUC:   0.5028\n",
      "\n",
      "XGBoost (Shuffled Labels):\n",
      "Accuracy:  0.4992\n",
      "F1 Score:  0.4979\n",
      "ROC AUC:   0.4960\n"
     ]
    }
   ],
   "source": [
    "#lightgbm and xgboost are the best performers.  shuffle tests for validation:\n",
    "from sklearn.utils import shuffle\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# --- Shuffle labels independently ---\n",
    "y_shuffled = y_full.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "X_shuffled = X_full.reset_index(drop=True)  # Align index with shuffled y\n",
    "\n",
    "# --- Train/test split and scale (on mismatched X/y) ---\n",
    "X_train, X_test, y_train_shuffled, y_test_shuffled = train_test_split(\n",
    "    X_shuffled, y_shuffled, test_size=0.3, stratify=y_shuffled, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# --- LightGBM on shuffled labels ---\n",
    "lgbm_clf = LGBMClassifier(verbose=-1)\n",
    "lgbm_clf.fit(X_train_scaled, y_train_shuffled)\n",
    "y_pred_lgbm = lgbm_clf.predict(X_test_scaled)\n",
    "y_proba_lgbm = lgbm_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# --- XGBoost on shuffled labels ---\n",
    "xgb_clf = XGBClassifier(eval_metric='logloss')\n",
    "xgb_clf.fit(X_train_scaled, y_train_shuffled)\n",
    "y_pred_xgb = xgb_clf.predict(X_test_scaled)\n",
    "y_proba_xgb = xgb_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# --- Results ---\n",
    "print(\"LightGBM (Shuffled Labels):\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test_shuffled, y_pred_lgbm):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test_shuffled, y_pred_lgbm):.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_score(y_test_shuffled, y_proba_lgbm):.4f}\\n\")\n",
    "\n",
    "print(\"XGBoost (Shuffled Labels):\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test_shuffled, y_pred_xgb):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test_shuffled, y_pred_xgb):.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_score(y_test_shuffled, y_proba_xgb):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef87a051-6b98-4c97-b35a-d673c03af150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM K-Fold ROC AUCs: [0.9651 0.9654 0.9639 0.9681 0.9664]\n",
      "Mean AUC: 0.9658 | Std Dev: 0.0014\n",
      "\n",
      "XGBoost K-Fold ROC AUCs: [0.9635 0.9643 0.9628 0.9676 0.965 ]\n",
      "Mean AUC: 0.9646 | Std Dev: 0.0017\n"
     ]
    }
   ],
   "source": [
    "#K-fold cross-validation for XGBoost & LightGBM\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# --- Full dataset (already preprocessed) ---\n",
    "X_full = X.copy()\n",
    "y_full = y.copy()\n",
    "\n",
    "# --- Scale entire dataset up front ---\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_full)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns, index=X.index) #will need to be a dataframe with named columns for the loop below\n",
    "\n",
    "\n",
    "# --- 5-Fold Stratified CV ---\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "lgbm_aucs = []\n",
    "xgb_aucs = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_scaled_df, y_full):\n",
    "    X_train, X_test = X_scaled_df.iloc[train_index], X_scaled_df.iloc[test_index]\n",
    "    y_train, y_test = y_full.iloc[train_index], y_full.iloc[test_index]\n",
    "\n",
    "    \n",
    "    # LightGBM\n",
    "    lgbm_model = LGBMClassifier(verbose=-1)\n",
    "    lgbm_model.fit(X_train, y_train)\n",
    "    lgbm_proba = lgbm_model.predict_proba(X_test)[:, 1]\n",
    "    lgbm_auc = roc_auc_score(y_test, lgbm_proba)\n",
    "    lgbm_aucs.append(lgbm_auc)\n",
    "    \n",
    "    # XGBoost\n",
    "    xgb_model = XGBClassifier(eval_metric='logloss')\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    xgb_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "    xgb_auc = roc_auc_score(y_test, xgb_proba)\n",
    "    xgb_aucs.append(xgb_auc)\n",
    "\n",
    "# --- Results ---\n",
    "print(\"LightGBM K-Fold ROC AUCs:\", np.round(lgbm_aucs, 4))\n",
    "print(f\"Mean AUC: {np.mean(lgbm_aucs):.4f} | Std Dev: {np.std(lgbm_aucs):.4f}\\n\")\n",
    "\n",
    "print(\"XGBoost K-Fold ROC AUCs:\", np.round(xgb_aucs, 4))\n",
    "print(f\"Mean AUC: {np.mean(xgb_aucs):.4f} | Std Dev: {np.std(xgb_aucs):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97eab939-299f-4c65-86ec-221e7a18bae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Logistic Regression – Shuffle Test\n",
      "ROC AUC (Shuffled): 0.5060\n",
      "\n",
      "L1 Logistic Regression – 5-Fold Cross-Validation\n",
      "AUCs: [0.9455 0.9493 0.9531 0.9418 0.9485]\n",
      "Mean AUC: 0.9476 | Std Dev: 0.0038\n"
     ]
    }
   ],
   "source": [
    "#L1-regularization we shuffle test and k-fold cross-validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "# --- Full dataset ---\n",
    "X_full = X.copy()\n",
    "y_full = y.copy()\n",
    "\n",
    "# --- Scale full data ---\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_full)\n",
    "\n",
    "# ------------------------------\n",
    "# Shuffle Test (L1 Logistic)\n",
    "# ------------------------------\n",
    "_, y_shuffled = shuffle(X_scaled, y_full)\n",
    "\n",
    "X_train, X_test, y_train_shuff, y_test_shuff = train_test_split(X_scaled, y_shuffled, test_size=0.3, stratify=y_shuffled)\n",
    "\n",
    "logreg_l1 = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000)\n",
    "logreg_l1.fit(X_train, y_train_shuff)\n",
    "y_proba_shuff = logreg_l1.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"L1 Logistic Regression – Shuffle Test\")\n",
    "print(f\"ROC AUC (Shuffled): {roc_auc_score(y_test_shuff, y_proba_shuff):.4f}\")\n",
    "print()\n",
    "\n",
    "# ------------------------------\n",
    "# 5-Fold Cross-Validation\n",
    "# ------------------------------\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "auc_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_scaled, y_full):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y_full.iloc[train_index], y_full.iloc[test_index]\n",
    "    \n",
    "    model = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    auc_scores.append(auc)\n",
    "\n",
    "print(\"L1 Logistic Regression – 5-Fold Cross-Validation\")\n",
    "print(\"AUCs:\", np.round(auc_scores, 4))\n",
    "print(f\"Mean AUC: {np.mean(auc_scores):.4f} | Std Dev: {np.std(auc_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c21b815-e3ff-4a86-92eb-493661f5ff45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP – Shuffle Test\n",
      "ROC AUC (Shuffled): 0.5011\n",
      "\n",
      "MLP – 5-Fold Cross-Validation\n",
      "AUCs: [0.8519 0.8484 0.8626 0.8712 0.8875]\n",
      "Mean AUC: 0.8643 | Std Dev: 0.0141\n"
     ]
    }
   ],
   "source": [
    "# validating the neural network model with shuffle test and k fold cross validation\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Assume X and y are ready and preprocessed (quantitative only, scaled)\n",
    "# X should be the same one used for the tuned MLP\n",
    "X_nn = X.copy()\n",
    "y_nn = y.copy()\n",
    "\n",
    "# =========================\n",
    "# Shuffle Test\n",
    "# =========================\n",
    "_, y_shuffled = shuffle(X_nn, y_nn)\n",
    "\n",
    "X_train, X_test, y_train_shuff, y_test_shuff = train_test_split(\n",
    "    X_nn, y_shuffled, test_size=0.3, stratify=y_shuffled\n",
    ")\n",
    "\n",
    "mlp_shuff = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', max_iter=1000)\n",
    "mlp_shuff.fit(X_train, y_train_shuff)\n",
    "y_proba_shuff = mlp_shuff.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"MLP – Shuffle Test\")\n",
    "print(f\"ROC AUC (Shuffled): {roc_auc_score(y_test_shuff, y_proba_shuff):.4f}\\n\")\n",
    "\n",
    "# =========================\n",
    "# 5-Fold Cross-Validation\n",
    "# =========================\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "auc_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_nn, y_nn):\n",
    "    X_train, X_test = X_nn.iloc[train_index], X_nn.iloc[test_index]\n",
    "    y_train, y_test = y_nn.iloc[train_index], y_nn.iloc[test_index]\n",
    "    \n",
    "    model = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    auc_scores.append(auc)\n",
    "\n",
    "print(\"MLP – 5-Fold Cross-Validation\")\n",
    "print(\"AUCs:\", np.round(auc_scores, 4))\n",
    "print(f\"Mean AUC: {np.mean(auc_scores):.4f} | Std Dev: {np.std(auc_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce5452d-6d69-4ff3-af29-5e1891ab4861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phoenix_pca]",
   "language": "python",
   "name": "conda-env-phoenix_pca-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
